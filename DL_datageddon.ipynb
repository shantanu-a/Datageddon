{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPnvGZrfe_xi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH1Bdo7pfBbq"
      },
      "outputs": [],
      "source": [
        "X = np.load('C:\\Data\\Datageddon/X.npy')  \n",
        "y = np.load('C:\\Data\\Datageddon/Y.npy')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R7qVMKJfDaV",
        "outputId": "f74e93f7-41d8-48c7-89ac-cae231d8992c"
      },
      "outputs": [],
      "source": [
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LCUShNcfFaI"
      },
      "outputs": [],
      "source": [
        "# You may change the train-test split according to your will\n",
        "X_train, y_train = X[:20000], y[:20000]\n",
        "X_val, y_val = X[20000:], y[20000:]\n",
        "#_val variables are basically test data variables\n",
        "\n",
        "\n",
        "X_train = torch.from_numpy(X_train).float()  \n",
        "y_train = torch.from_numpy(y_train).long()   \n",
        "X_val = torch.from_numpy(X_val).float()  \n",
        "y_val = torch.from_numpy(y_val).long().reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJRSHKasfHjt"
      },
      "outputs": [],
      "source": [
        "#batch size is the number of attributes processed until the model is updated\n",
        "batch_size = 32\n",
        "\n",
        "#Dataloader is used to load our data while Dataset is used to wrap an iterable around it to allow easy access\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vAaBPAIBd3f",
        "outputId": "4cbd7cfe-1154-4c02-ae61-bbfd2bb14cc8"
      },
      "outputs": [],
      "source": [
        "#Actual implementation of deep neural network(3 layered DL)\n",
        "#Activation function used is relu i.e max(0,x)\n",
        "import torch.nn.functional as F\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1=nn.Linear(64*3*3*3,512)\n",
        "    self.fc2=nn.Linear(512,64)\n",
        "    self.fc3=nn.Linear(64,4)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=x.view(-1,64*3*3*3).clone()\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return x\n",
        "model=Net()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxsfTaMzEFCE"
      },
      "outputs": [],
      "source": [
        "#We are optimizing our DL network and defining loss function.\n",
        "import torch.optim as optim\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbWXkzD2IlFL",
        "outputId": "52ac143d-5b67-41c1-af55-74696f040e82"
      },
      "outputs": [],
      "source": [
        "#This is the code for training our neural network. I am printing the loss for each epoch to see that the loss is reducing.\n",
        "i=1\n",
        "for epoch in range(20):\n",
        "    train_loss = 0.\n",
        "    for local_batch, local_labels in train_dataloader:\n",
        "        y_pred = model(local_batch)\n",
        "        loss = loss_fn(y_pred,local_labels)\n",
        "        train_loss += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    train_loss/=batch_size\n",
        "    print(f\"Epoch {i} loss : \", train_loss)\n",
        "    i+=1\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHCotziycGML",
        "outputId": "19ddbfa1-41e1-4598-d387-eb02a115bbfb"
      },
      "outputs": [],
      "source": [
        "# Accuracy of training dataset\n",
        "acc = 0.\n",
        "count = 0\n",
        "with torch.set_grad_enabled(False):\n",
        "  for local_batch, local_labels in train_dataloader:\n",
        "    #predict the label\n",
        "    y_pred = model(local_batch)\n",
        "    #find the index of the element with max weight which will give us the label.\n",
        "    y_pred = torch.argmax(y_pred, dim = 1)\n",
        "    #then we check if that label is same as the given label(for accuracy measurements)\n",
        "\n",
        "    for i in range(local_labels.shape[0]):\n",
        "      if local_labels[i] == y_pred[i]:\n",
        "        acc = 1./(count+1) + acc*count/(count + 1)\n",
        "      else:\n",
        "        acc = acc*count/(count + 1)\n",
        "      count += 1\n",
        "    \n",
        "print(f\"Accuracy {acc*100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W64tTBo9KBmw",
        "outputId": "4b73fdb4-f602-43a1-d5e5-e4b4ff4e8ea3"
      },
      "outputs": [],
      "source": [
        "# Accuracy of validation dataset\n",
        "acc = 0.\n",
        "count = 0\n",
        "with torch.set_grad_enabled(False):\n",
        "  for local_batch, local_labels in val_dataloader:\n",
        "    y_pred = model(local_batch)\n",
        "    y_pred = torch.argmax(y_pred, dim = 1)\n",
        "\n",
        "    for i in range(local_labels.shape[0]):\n",
        "      if local_labels[i] == y_pred[i]:\n",
        "        acc = 1./(count+1) + acc*count/(count + 1)\n",
        "      else:\n",
        "        acc = acc*count/(count + 1)\n",
        "      count += 1\n",
        "    \n",
        "print(f\"Accuracy {acc*100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKbAdhtFdRZk"
      },
      "outputs": [],
      "source": [
        "#saving the weights and other parameters for the model\n",
        "#Since I was working on google colab, the file path is as below. If you want to save on your local machine, comment out the existing path and use the other file path\n",
        "filepath='/content/drive/MyDrive/Datageddon_files/weights.pt'\n",
        "# filepath='Datageddon/weights.pt'\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, filepath)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
